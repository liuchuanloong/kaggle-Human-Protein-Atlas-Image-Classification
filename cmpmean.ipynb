{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pathlib\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import PIL\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiBandMultiLabelDataset(Dataset):\n",
    "    BANDS_NAMES = ['_red.png', '_green.png', '_blue.png', '_yellow.png']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_df)\n",
    "\n",
    "    def __init__(self, images_df,\n",
    "                 base_path,\n",
    "                 image_transform,\n",
    "                 augmentator=None,\n",
    "                 train_mode=True\n",
    "                 ):\n",
    "        if not isinstance(base_path, pathlib.Path):\n",
    "            base_path = pathlib.Path(base_path)\n",
    "\n",
    "        self.images_df = images_df.copy()\n",
    "        self.image_transform = image_transform\n",
    "        self.augmentator = augmentator\n",
    "        self.images_df.Id = self.images_df.Id.apply(lambda x: base_path / x)\n",
    "        self.mlb = MultiLabelBinarizer(classes=list(LABEL_MAP.keys()))\n",
    "        self.train_mode = train_mode\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        y = None\n",
    "        X = self._load_multiband_image(index)\n",
    "        if self.train_mode:\n",
    "            y = self._load_multilabel_target(index)\n",
    "\n",
    "        # augmentator can be for instance imgaug augmentation object\n",
    "        if self.augmentator is not None:\n",
    "            X = self.augmentator(X)\n",
    "\n",
    "        X = self.image_transform(X)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def _load_multiband_image(self, index):\n",
    "        row = self.images_df.iloc[index]\n",
    "        image_bands = []\n",
    "        for band_name in self.BANDS_NAMES:\n",
    "            p = str(row.Id.absolute()) + band_name\n",
    "            pil_channel = PIL.Image.open(p).convert('L')\n",
    "            image_bands.append(pil_channel)\n",
    "\n",
    "        # lets pretend its a RBGA image to support 4 channels\n",
    "        band4image = PIL.Image.merge('RGBA', bands=image_bands)\n",
    "        band4image = np.array(band4image)\n",
    "        return band4image\n",
    "\n",
    "    def _load_multilabel_target(self, index):\n",
    "        return list(map(int, self.images_df.iloc[index].Target.split(' ')))\n",
    "\n",
    "    def collate_func(self, batch):\n",
    "        labels = None\n",
    "        images = [x[0] for x in batch]\n",
    "\n",
    "        if self.train_mode:\n",
    "            labels = [x[1] for x in batch]\n",
    "            labels_one_hot = self.mlb.fit_transform(labels)\n",
    "            labels = torch.FloatTensor(labels_one_hot)\n",
    "\n",
    "        return torch.stack(images), labels\n",
    "\n",
    "    def visualize_sample(self, sample_size):\n",
    "        samples = np.random.choice(self.df['id'].values, sample_size)\n",
    "        self.df.set_index('id', inplace=True)\n",
    "        fig, axs = plt.subplots(2, sample_size)\n",
    "        for i in range(sample_size):\n",
    "            im = cv2.imread(self.df.loc[samples[i], 'im_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(self.df.loc[samples[i], 'mask_path'], cv2.IMREAD_GRAYSCALE)\n",
    "            print('Image shape: ', np.array(im).shape)\n",
    "            print('Mask shape: ', np.array(mask).shape)\n",
    "            axs[0, i].imshow(im)\n",
    "            axs[1, i].imshow(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "0: \"Nucleoplasm\" ,\n",
    "1: \"Nuclear membrane\"   ,\n",
    "2: \"Nucleoli\"   ,\n",
    "3: \"Nucleoli fibrillar center\",\n",
    "4: \"Nuclear speckles\"   ,\n",
    "5: \"Nuclear bodies\"   ,\n",
    "6: \"Endoplasmic reticulum\"   ,\n",
    "7: \"Golgi apparatus\"  ,\n",
    "8: \"Peroxisomes\"   ,\n",
    "9:  \"Endosomes\"   ,\n",
    "10: \"Lysosomes\"   ,\n",
    "11: \"Intermediate filaments\"  ,\n",
    "12: \"Actin filaments\"   ,\n",
    "13: \"Focal adhesion sites\"  ,\n",
    "14: \"Microtubules\"   ,\n",
    "15: \"Microtubule ends\"   ,\n",
    "16: \"Cytokinetic bridge\"   ,\n",
    "17: \"Mitotic spindle\"  ,\n",
    "18: \"Microtubule organizing center\",\n",
    "19: \"Centrosome\",\n",
    "20: \"Lipid droplets\"   ,\n",
    "21: \"Plasma membrane\"  ,\n",
    "22: \"Cell junctions\"   ,\n",
    "23: \"Mitochondria\"   ,\n",
    "24: \"Aggresome\"   ,\n",
    "25: \"Cytosol\" ,\n",
    "26: \"Cytoplasmic bodies\",\n",
    "27: \"Rods & rings\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_IMAGES = './data/full_train/'\n",
    "PATH_TO_TEST_IMAGES = './data/test/'\n",
    "PATH_TO_META = './data/full_dev_train.csv'\n",
    "SAMPLE_SUBMI = './data/sample_submission.csv'\n",
    "\n",
    "SEED = 666\n",
    "DEV_MODE = False\n",
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_TO_META)\n",
    "print(len(df))\n",
    "def image_transform(img):\n",
    "    # img = self.normalize(img)\n",
    "#     mean = []\n",
    "#     std = []\n",
    "#     img = cv2.resize(img, (self.size, self.size))\n",
    "    img = np.array(img).transpose(2,0,1).astype('float32')\n",
    "    img = torch.from_numpy(img)\n",
    "#     img = transforms.functional.normalize(img, mean=mean, std=std)\n",
    "    return img\n",
    " \n",
    "gtrain = MultiBandMultiLabelDataset(df, base_path=PATH_TO_IMAGES, image_transform=image_transform)\n",
    "\n",
    "train_load = DataLoader(gtrain, collate_fn=gtrain.collate_func, batch_size=16, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, lists in enumerate(tqdm_notebook(train_load)):\n",
    "#     if i > 1:\n",
    "#         break\n",
    "#     img = lists[0].numpy()\n",
    "#     print(img[0, :, :, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = []\n",
    "s0 = []\n",
    "m1 = []\n",
    "s1 = []\n",
    "m2 = []\n",
    "s2 = []\n",
    "m3 = []\n",
    "s3 = []\n",
    "\n",
    "for i, lists in enumerate(tqdm_notebook(train_load)):\n",
    "    img = lists[0].numpy()\n",
    "    mean0 = np.mean(img[:, :, :, 0])\n",
    "    std0 = np.std(img[:, :, :, 0])\n",
    "    m0.append(mean0)\n",
    "    s0.append(std0)\n",
    "    \n",
    "    mean1 = np.mean(img[:, :, :, 1])\n",
    "    std1 = np.std(img[:, :, :, 1])\n",
    "    m1.append(mean1)\n",
    "    s1.append(std1)\n",
    "\n",
    "    \n",
    "    mean2 = np.mean(img[:, :, :, 2])\n",
    "    std2 = np.std(img[:, :, :, 2])\n",
    "    m2.append(mean2)\n",
    "    s2.append(std2)\n",
    "\n",
    "    mean3 = np.mean(img[:, :, :, 3])\n",
    "    std3 = np.std(img[:, :, :, 3])\n",
    "    m3.append(mean3)\n",
    "    s3.append(std3)\n",
    "\n",
    "mm0 = np.mean(m0, axis=0)\n",
    "ss0 = np.mean(s0)\n",
    "mm1 = np.mean(m1)\n",
    "ss1 = np.mean(s1)\n",
    "mm2 = np.mean(m2)\n",
    "ss2 = np.mean(s2)\n",
    "mm3 = np.mean(m3)\n",
    "ss3 = np.mean(s3)\n",
    "print(mm0, mm1, mm2, mm3)\n",
    "print(ss0, ss1, ss2, ss3)\n",
    "m = 'mean: ({}, {}, {}, {})'.format(mm0, mm1, mm2, mm3)\n",
    "s = 'std: ({}, {}, {}, {})'.format(ss0, ss1, ss2, ss3)\n",
    "with open('./data/mean&std.txt', 'a+') as f:\n",
    "    f.write(m)\n",
    "    f.write(s)\n",
    "#     for j, img in enumerate(lists[0]):\n",
    "#         img = img.numpy().transpose((1, 2, 0))\n",
    "#         if i > 1:\n",
    "#             break\n",
    "#         plt.imshow(img[:,:,0], cmap='Greens')\n",
    "#         plt.show()\n",
    "#         plt.imshow(img[:,:,1], cmap='Reds')\n",
    "#         plt.show()\n",
    "#         plt.imshow(img[:,:,2], cmap='Oranges')\n",
    "#         plt.show()\n",
    "#         plt.imshow(img[:,:,3], cmap='Blues')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
